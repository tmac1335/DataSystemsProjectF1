{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "def construct_sparql_query(user_query):\n",
    "    with open('../data/ontology_description.txt', 'r') as file:\n",
    "        ontology_description = file.read()\n",
    "    \n",
    "    task = \"\"\"\n",
    "        Task:\n",
    "        You are an assistant trained to generate SPARQL queries based on the given ontology and user prompts. Use the ontology description to understand the structure and generate accurate queries. Assume the ontology is loaded in a database.\n",
    "        only return the sparql query.\n",
    "        \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Ontology Description:\n",
    "    {ontology_description}\n",
    "\n",
    "    {task}\n",
    "\n",
    "    User Query:\n",
    "    {user_query}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-reasoner\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    choice_str = response.choices[0].message.content\n",
    "    \n",
    "    return choice_str\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
