{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rule based model, which works to tackle some issues with working with LLMs such as hallucinations and reasoning. The main idea is that we will essentially have a dictionary that classifies each word from the query, and we sort of mechanically construct the query from there. How we do it? I'm not really sure yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from difflib import get_close_matches\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Dummy data for entity types and relationship types in the linked database\n",
    "ENTITY_TYPES = [\n",
    "    \"Contractor\",\n",
    "    \"ConstructionProject\",\n",
    "    \"Location\",\n",
    "    \"Material\",\n",
    "    \"Supplier\",\n",
    "    \"LightBulbModel\",\n",
    "    \"ConcreteType\",\n",
    "    \"SteelType\",\n",
    "    \"WoodType\"\n",
    "]\n",
    "RELATIONSHIP_TYPES = [\n",
    "    \"constructed\",\n",
    "    \"locatedAt\",\n",
    "    \"usesMaterial\",\n",
    "    \"suppliedBy\",\n",
    "    \"managedBy\",\n",
    "    \"sourcedFrom\",\n",
    "    \"employs\",\n",
    "    \"containsLightBulbModel\",\n",
    "    \"containsConcreteType\",\n",
    "    \"containsSteelType\",\n",
    "    \"containsWoodType\"\n",
    "]\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "organisation = os.getenv('ORGANISATION')\n",
    "client = OpenAI(organization=organisation, api_key=api_key)\n",
    "\n",
    "def find_closest_matches(query_terms, valid_terms):\n",
    "    \"\"\"\n",
    "    Find the closest matches for query terms from a list of valid terms.\n",
    "    \"\"\"\n",
    "    matches = {}\n",
    "    for term in query_terms:\n",
    "        close_match = get_close_matches(term, valid_terms, n=1, cutoff=0.5)\n",
    "        if close_match:\n",
    "            matches[term] = close_match[0]\n",
    "    return matches\n",
    "\n",
    "def extract_entities_and_relationships(nl_query):\n",
    "    \"\"\"\n",
    "    Use GPT to extract entities and relationships from the natural language query.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract the entities, filters, and relationships from the following construction-related query and return a sparql query that can be used to query the linked database:\n",
    "    \"{nl_query}\"\n",
    "    Provide a JSON object with three keys: `entities`, `filters`, and `relationships`. \n",
    "    - `entities` is a list of entity types mentioned.\n",
    "    - `filters` is an object with keys `attribute`, `value`, and `entity`.\n",
    "    - `relationships` is a list of objects with keys `from`, `to`, and `relationship`.\n",
    "    - `Here is a list of entities and relationships in the database, so use those to find the closest related ones`: entitites: \"{ENTITY_TYPES}\", relationships: \"{RELATIONSHIP_TYPES}\n",
    "    - ``\n",
    "    \n",
    "    \"\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    choice_str = response.choices[0].message.content\n",
    "    json_match = re.search(r'\\{.*\\}', choice_str, re.DOTALL)\n",
    "\n",
    "    if json_match:\n",
    "        # Extract the JSON string\n",
    "        json_string = json_match.group(0)\n",
    "        \n",
    "        # Parse the JSON string into a Python dictionary\n",
    "        choice_object = json.loads(json_string)\n",
    "        \n",
    "        return choice_object\n",
    "    else:\n",
    "        return {\"entities\": [], \"filters\": {}, \"relationships\": []}\n",
    "\n",
    "def construct_sparql_query(nl_query):\n",
    "    \"\"\"\n",
    "    Construct a SPARQL query from a natural language query.\n",
    "    \"\"\"\n",
    "    # Extract entities and relationships using GPT\n",
    "    extracted_data = extract_entities_and_relationships(nl_query)\n",
    "    print(extracted_data)\n",
    "\n",
    "    entities = extracted_data.get('entities', [])\n",
    "    filters = extracted_data.get('filters', {})\n",
    "    relationships = extracted_data.get('relationships', [])\n",
    "    \n",
    "    sparql_query = \"SELECT ?subject ?predicate ?object WHERE {\\n\"\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity_type = find_closest_matches([entity], ENTITY_TYPES).get(entity, entity)\n",
    "        sparql_query += f\"  ?subject rdf:type :{entity_type} .\\n\"\n",
    "    \n",
    "    for relationship in relationships:\n",
    "        from_entity = find_closest_matches([relationship['from']], ENTITY_TYPES).get(relationship['from'], relationship['from'])\n",
    "        to_entity = find_closest_matches([relationship['to']], ENTITY_TYPES).get(relationship['to'], relationship['to'])\n",
    "        relationship_type = find_closest_matches([relationship['relationship']], RELATIONSHIP_TYPES).get(relationship['relationship'], relationship['relationship'])\n",
    "        sparql_query += f\"  ?{from_entity} :{relationship_type} ?{to_entity} .\\n\"\n",
    "    \n",
    "    if filters:\n",
    "        attribute = filters.get('attribute')\n",
    "        value = filters.get('value')\n",
    "        entity = filters.get('entity')\n",
    "        entity_type = find_closest_matches([entity], ENTITY_TYPES).get(entity, entity)\n",
    "        sparql_query += f\"  ?{entity_type} :{attribute} \\\"{value}\\\" .\\n\"\n",
    "    \n",
    "    sparql_query += \"}\"\n",
    "    \n",
    "    return sparql_query\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nl_query = \"buildings constructed in new york after 2009\"\n",
    "    sparql_query = construct_sparql_query(nl_query)\n",
    "    print(\"Generated SPARQL Query:\\n\", sparql_query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
